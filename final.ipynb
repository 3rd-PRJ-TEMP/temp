{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c34e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_5164\\1998050127.py:171: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()  # 매 배치 후 즉시 저장\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "\n",
    "# 파일 로드 및 doc 화\n",
    "file_paths = {\n",
    "    \"term\": \"./metadata/term.json\",\n",
    "    \"load_traffic_law\": \"./metadata/load_traffic_law.json\",\n",
    "    \"modifier\": \"./metadata/modifier.json\",\n",
    "    \"car_case\": \"./metadata/car_to_car.json\",\n",
    "    \"precedent\": \"./metadata/precedent.json\"\n",
    "}\n",
    "\n",
    "# 교통사고 케이스용 필드 상수\n",
    "CASE_ID = \"사건 ID\"\n",
    "CASE_TITLE = \"사건 제목\"\n",
    "CASE_SITUATION = \"사고상황\"\n",
    "BASE_RATIO = \"기본 과실비율\"\n",
    "MODIFIERS = \"케이스별 과실비율 조정예시\"\n",
    "LAW_REFERENCES = \"관련 법규\"\n",
    "PRECEDENT = \"참고 판례\"\n",
    "REASON = \"기본 과실비율 해설\"\n",
    "\n",
    "# JSON 로드 함수\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 리스트형 JSON 변환 (term, modifier, law_meta)\n",
    "def convert_list_to_documents(data_list, doc_type):\n",
    "    return [\n",
    "        Document(page_content=json.dumps(item, ensure_ascii=False), metadata={\"type\": doc_type})\n",
    "        for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_precedent_documents(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item['court']} {item['case_id']} : {item['content']}\",\n",
    "            metadata={\n",
    "                \"court\": item[\"court\"],\n",
    "                \"case_id\": item[\"case_id\"],\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_term_documents(data_list):\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=f\"{item['term']} : {item['desc']}\",\n",
    "            metadata={\n",
    "                \"term\": item[\"term\"]\n",
    "            }\n",
    "        ) for item in data_list\n",
    "    ]\n",
    "\n",
    "def convert_car_case_documents(data_list):\n",
    "    documents = []\n",
    "\n",
    "    def safe_value(value):\n",
    "        if isinstance(value, list):\n",
    "            return \", \".join(map(str, value))\n",
    "        elif isinstance(value, dict):\n",
    "            return json.dumps(value, ensure_ascii=False)\n",
    "        elif value is None:\n",
    "            return \"\"  # null도 허용 안 되므로 빈 문자열로 처리\n",
    "        else:\n",
    "            return str(value)\n",
    "\n",
    "    for item in data_list:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "\n",
    "        # page_content는 원본 전체 JSON 문자열\n",
    "        content = json.dumps(item, ensure_ascii=False)\n",
    "\n",
    "        # 기본 과실비율 해설이 리스트일 수 있음 → 문자열로 병합\n",
    "        reason = item.get(REASON)\n",
    "        if isinstance(reason, list):\n",
    "            reason = \"\\n\".join(map(str, reason))\n",
    "\n",
    "        metadata = {\n",
    "            \"type\": \"car_case\",\n",
    "            \"id\": safe_value(item.get(CASE_ID)),\n",
    "            \"title\": safe_value(item.get(CASE_TITLE)),\n",
    "            \"situation\": safe_value(item.get(CASE_SITUATION)),\n",
    "            \"base_ratio\": safe_value(item.get(BASE_RATIO)),\n",
    "            \"modifiers\": safe_value(item.get(MODIFIERS)),\n",
    "            \"load_traffic_law\": safe_value(item.get(LAW_REFERENCES)),\n",
    "            \"precedent\": safe_value(item.get(PRECEDENT)),\n",
    "            \"reason\": safe_value(reason)\n",
    "        }\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "# 도로교통법 law JSON → 문서화\n",
    "def convert_law_json_to_documents(data_dict):\n",
    "    documents = []\n",
    "\n",
    "    def normalize(item):\n",
    "        return json.dumps(item, ensure_ascii=False) if isinstance(item, dict) else str(item)\n",
    "\n",
    "    for law_name, content in data_dict.items():\n",
    "        if isinstance(content, dict):\n",
    "            for clause, text in content.items():\n",
    "                lines = [normalize(x) for x in (text if isinstance(text, list) else [text])]\n",
    "                full_text = f\"{law_name} {clause}\\n\" + \"\\n\".join(lines)\n",
    "                documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "        else:\n",
    "            lines = [normalize(x) for x in (content if isinstance(content, list) else [content])]\n",
    "            full_text = f\"{law_name}\\n\" + \"\\n\".join(lines)\n",
    "            documents.append(Document(page_content=full_text, metadata={\"type\": \"load_traffic_law\"}))\n",
    "    \n",
    "    return documents\n",
    "    \n",
    "\n",
    "import random\n",
    "json_precedent = load_json(file_paths[\"precedent\"])\n",
    "random_precedent = random.sample(json_precedent, 10)\n",
    "# for precedent in random_precedent:\n",
    "#     print(precedent['court'])\n",
    "#     print(precedent['case_id'])\n",
    "\n",
    "# 문서화 실행\n",
    "term_docs = convert_term_documents(load_json(file_paths[\"term\"]))\n",
    "modifier_docs = convert_list_to_documents(load_json(file_paths[\"modifier\"]), \"modifier\")\n",
    "precedent_docs = convert_precedent_documents(load_json(file_paths[\"precedent\"]))\n",
    "car_case_docs = convert_car_case_documents(load_json(file_paths[\"car_case\"]))\n",
    "load_traffic_law_docs = convert_law_json_to_documents(load_json(file_paths[\"load_traffic_law\"]))\n",
    "\n",
    "\n",
    "# 전체 문서 리스트\n",
    "all_docs = term_docs + modifier_docs + car_case_docs + precedent_docs + load_traffic_law_docs\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma  # persist 지원\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 청크 크기 조정 (500~1000 권장)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\\\. )\", \" \", \"\"],\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "\n",
    "# 2. 문서 분할\n",
    "all_splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# 4. Chroma DB에 배치 처리로 저장\n",
    "batch_size = 100  # 한 번에 처리할 청크 수\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits[:batch_size],  # 첫 배치\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./vectordb\"\n",
    ")\n",
    "\n",
    "# 남은 청크를 순차적으로 추가 \n",
    "for i in range(0, len(all_splits), batch_size):\n",
    "    try:\n",
    "        batch = all_splits[i:i+batch_size]\n",
    "        vectorstore.add_documents(batch)\n",
    "        vectorstore.persist()  # 매 배치 후 즉시 저장\n",
    "    except Exception as e:\n",
    "        print(f\"배치 {i}~{i+batch_size} 저장 실패: {e}\")\n",
    "\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9e2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚗 교통사고 AI 분석기입니다.\n",
      "사고 상황이나 알고 싶은 법률/판례 정보를 입력해 주세요.\n",
      "\n",
      "📘 결과 출력:\n",
      "\n",
      "[판례 설명 결과]\n",
      "- 용어/조항 정의: 동일폭 교차로와 대로/소로 교차로는 도로의 폭에 따라 교차로에서의 과실 여부 및 가해자와 피해자의 구분이 달라질 수 있는 중요한 요소입니다. 대로와 소로의 구분은 도로의 폭을 기준으로 하며, 이는 상대적인 개념입니다. 대로와 소로의 구분은 엄격하게 적용되어야 하며, 진행한 도로를 기준으로 하고, 계측으로 구분하는 것이 아니라 운전자가 일견 분별할 수 있어야 합니다.\n",
      "- 출처가 명시된 경우: 판례(대법원 97다14187)\n"
     ]
    }
   ],
   "source": [
    "# 기능 분류 및 라우팅 처리 + 사고 상황 기반 과실비율 판단 포함\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "# 함수 정의 (사고 상황 입력시)\n",
    "def assess_accident_fault(user_input: str, all_docs: list) -> str:\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import re\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from langchain.schema import Document\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import LLMChain\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    # car_case 문서 필터링 및 사고상황 추출\n",
    "    case_docs = [doc for doc in all_docs if doc.metadata.get(\"type\") == \"car_case\"]\n",
    "    case_texts = [doc.metadata.get(\"situation\", \"\") for doc in case_docs if doc.metadata.get(\"situation\")]\n",
    "\n",
    "    # ko-sbert 임베딩\n",
    "    embed_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "    case_embeddings = embed_model.encode(case_texts)\n",
    "\n",
    "    # 사용자 입력\n",
    "    query_embedding = embed_model.encode([user_input])[0]\n",
    "\n",
    "    # 코사인 유사도 계산 및 Top-3 추출\n",
    "    cos_similarities = np.dot(case_embeddings, query_embedding) / (\n",
    "        np.linalg.norm(case_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "    )\n",
    "    top_k_idx = np.argsort(cos_similarities)[-3:][::-1]\n",
    "    top_candidates = [case_docs[i] for i in top_k_idx]\n",
    "\n",
    "    # 판례 요약 출력\n",
    "    def summarize(doc, idx):\n",
    "        return f\"{idx+1}. 사건 ID: {doc.metadata.get('id')}\\n사고상황: {doc.metadata.get('situation')}\"\n",
    "\n",
    "    case_summaries = \"\\n\\n\".join([summarize(doc, i) for i, doc in enumerate(top_candidates)])\n",
    "\n",
    "    # GPT - 사건ID 선택(3개 중에 하나 판단)\n",
    "    selection_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"case_summaries\"],\n",
    "        template=\"\"\"\n",
    "    [사용자 입력 사고 상황]\n",
    "    {user_input}\n",
    "\n",
    "    [후보 판례 3건]\n",
    "    {case_summaries}\n",
    "\n",
    "    위 3건 중, 사고의 전개 구조(예: 직진 vs 좌회전, 도로 외 장소에서 진입, 교차로 내 진입 여부 등)가 사용자 상황과 가장 유사한 **사건 ID** 하나를 선택하세요.\n",
    "\n",
    "    반드시 다음 기준을 고려하세요:\n",
    "    - 차량들의 위치와 진입 경로가 유사한가?\n",
    "    - 사고 발생 지점과 방향이 유사한가?\n",
    "    - 각 차량의 신호·우선권 상황이 유사한가?|\n",
    "    - 도로 구조(교차로, 신호 유무, 도로 외 장소 등)가 유사한가?\n",
    "\n",
    "    출력 형식 (고정):\n",
    "    - 사건 ID: 차XX-X\n",
    "    - 판단 근거: (선택한 이유. 단순 유사성이 아니라, 어떤 지점이 유사했는지 명확히 설명할 것)\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    selection_chain = LLMChain(llm=llm, prompt=selection_prompt)\n",
    "    selection_result = selection_chain.run(user_input=user_input, case_summaries=case_summaries)\n",
    "\n",
    "    # 사건 ID 파싱 및 선택\n",
    "    match = re.search(r\"사건 ID[:：]?\\s*(차\\d{1,2}-\\d{1,2})\", selection_result)\n",
    "    selected_id = match.group(1) if match else None\n",
    "    selected_doc = next((doc for doc in case_docs if doc.metadata.get(\"id\") == selected_id), None)\n",
    "\n",
    "    # 최종 판단 GPT 프롬프트(선택한 사건 object 내에서 과실비율 판단)\n",
    "    if selected_doc:\n",
    "        # 해당 사건 관련 보조 문서들을 함께 전달\n",
    "        related_docs = [doc for doc in all_docs if selected_id in doc.page_content]\n",
    "        context_str = \"\\n\\n\".join(doc.page_content for doc in related_docs)\n",
    "\n",
    "        final_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_input\", \"case_data\"],\n",
    "            template=\"\"\"\n",
    "    너는 교통사고 과실 판단 전문가야.\n",
    "    아래 '사고 상황'을 분석하여 핵심 요소를 구조화하고, 반드시 문서 내에서 가장 유사한 사례(case)를 찾아 과실비율을 판단해줘.\n",
    "\n",
    "    ---\n",
    "\n",
    "    사고 상황 원문:\n",
    "    {user_input}\n",
    "\n",
    "    ➤ 사고 상황 요약 (다음 항목 기준):\n",
    "    - A차량 신호 및 진행 방식:\n",
    "    - B차량 신호 및 진행 방식:\n",
    "    - 충돌 방식 및 위치:\n",
    "    - 교차로/신호기 유무 등 도로 환경:\n",
    "\n",
    "    문서:\n",
    "    {case_data}\n",
    "\n",
    "    출력 형식 (고정):\n",
    "    1. 과실비율: A차량 xx% vs B차량 xx%\n",
    "    2. 판단 근거 요약\n",
    "    3. 적용 법률:\n",
    "    - [법률명] 제[조]조 [항]\n",
    "    4. 참고 판례:\n",
    "    - [법원명] [사건번호]\n",
    "\n",
    "    조건:\n",
    "    - 반드시 문서 내 유사 사례를 기반으로 판단해야 해.\n",
    "    - 유사 사례와 현재 사고 상황이 정확히 일치하지 않으면, 차이점을 명시하고 과실비율 조정 이유를 설명해.\n",
    "    - 추측이나 상식은 사용하지 말고, 문서 정보만을 기반으로 판단해.\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "        final_chain = LLMChain(llm=llm, prompt=final_prompt)\n",
    "        final_result = final_chain.run(user_input=user_input, case_data=context_str)\n",
    "\n",
    "        print(f\"\\n선택된 사건 ID: {selected_id}\")\n",
    "        print(\"GPT 최종 판단 결과:\\n\")\n",
    "        print(final_result)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n❌ 사건 ID를 정확히 선택하지 못했습니다.\")\n",
    "        print(\"GPT 응답:\\n\", selection_result)\n",
    "\n",
    "# 함수 정의 (용어/판례 입력시)\n",
    "def precedent_result(user_input):\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain.chains.query_constructor.base import AttributeInfo\n",
    "    from langchain.retrievers import SelfQueryRetriever\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)    \n",
    "\n",
    "    # 메타데이터 필드 정의 (필수!)\n",
    "    metadata_field_info = [\n",
    "        AttributeInfo(\n",
    "            name=\"court\",\n",
    "            description=\"판례의 법원명 (예: 대법원, 서울고등법원 등)\",\n",
    "            type=\"string\"\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"case_id\",\n",
    "            description=\"사건번호 (예: 92도2077)\",\n",
    "            type=\"string\"\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"term\",\n",
    "            description=\"용어\",\n",
    "            type=\"string\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # SelfQueryRetriever 생성 (metadata_field_info 필수)\n",
    "    self_retriever = SelfQueryRetriever.from_llm(\n",
    "        llm=llm,\n",
    "        vectorstore=vectorstore,\n",
    "        document_contents=\"교통사고 판례 데이터\",\n",
    "        metadata_field_info=metadata_field_info  # ✅ 반드시 필요\n",
    "    )\n",
    "\n",
    "\n",
    "    # 프롬프트 구성\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"context\"],\n",
    "        template=\"\"\"아래 문서 내용을 바탕으로 사용자가 물어본 용어나 법률 조항, 판례에 대해 정확하고 간결하게 설명해 주세요.\n",
    "        \n",
    "        질문: {question}\n",
    "        \n",
    "        문서: {context}\n",
    "\n",
    "        답변 형식:\n",
    "        - 용어/조항 정의: [정확한 설명]\n",
    "        - 출처가 명시된 경우: 관련 법률/조문 번호/판례명을 반드시 포함\n",
    "\n",
    "        답변:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # QA 체인 구성 및 실행\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=self_retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": user_input})\n",
    "    return f\"[판례 설명 결과]\\n{result['result']}\" \n",
    "\n",
    "routing_prompt = PromptTemplate.from_template(\"\"\"\n",
    "너는 교통사고 전문 AI 비서야.\n",
    "\n",
    "다음 사용자 질문을 읽고, 아래 중 어떤 기능을 사용해야 할지 하나만 골라줘:\n",
    "- 사고상황 과실비율 판단: \"function_1\"\n",
    "- 판례에 대한 설명 및용어 설명: \"function_2\"\n",
    "\n",
    "반드시 아래 형식으로만 대답해:\n",
    "[선택된 함수]: function_X\n",
    "[선택 이유]: (간단한 이유 설명)\n",
    "\n",
    "질문: {user_input}\n",
    "\"\"\")\n",
    "\n",
    "# 라우팅 함수\n",
    "def route_and_respond(user_input: str, all_docs: list) -> str:\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "    routing_chain = LLMChain(llm=llm, prompt=routing_prompt)\n",
    "    result = routing_chain.run(user_input=user_input)\n",
    "\n",
    "    match = re.search(r\"function_\\d\", result)\n",
    "    if match:\n",
    "        chosen = match.group()\n",
    "        if chosen == \"function_1\":\n",
    "            return assess_accident_fault(user_input, all_docs)\n",
    "        elif chosen == \"function_2\":\n",
    "            return precedent_result(user_input)\n",
    "    else:\n",
    "        return f\"❌ 기능 분류 실패.\\nGPT 응답: {result}\"\n",
    "    \n",
    "\n",
    "# 프로그램 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚗 교통사고 AI 분석기입니다.\")\n",
    "    print(\"사고 상황이나 알고 싶은 법률/판례 정보를 입력해 주세요.\")\n",
    "    user_input = input(\"입력 > \").strip()\n",
    "\n",
    "    if user_input:\n",
    "        result = route_and_respond(user_input, all_docs)\n",
    "        print(\"\\n📘 결과 출력:\\n\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"❌ 입력이 비어있습니다. 프로그램을 종료합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4d210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "pystudy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
